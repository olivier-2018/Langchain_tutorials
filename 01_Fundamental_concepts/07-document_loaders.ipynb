{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a4f31f",
   "metadata": {},
   "source": [
    "# Document loaders\n",
    "\n",
    "Document Loaders are responsible for loading documents from a variety of sources.\n",
    "\n",
    "- load PDF files\n",
    "- load web pages\n",
    "- load CSV data\n",
    "- load data from a directory\n",
    "- load HTML data\n",
    "- load JSON data\n",
    "- load Markdown data\n",
    "- load Microsoft Office data\n",
    "- write a custom document loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb6bfd",
   "metadata": {},
   "source": [
    "# Load pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe20e1b",
   "metadata": {},
   "source": [
    "### Read pdf text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8258feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA: Open and Efﬁcient Foundation Language Models\n",
      "Hugo Touvron∗, Thibaut Lavril∗, Gautier Izacard ∗, Xavier Martinet\n",
      "Marie-Anne Lachaux, Timothee Lacroix, Baptiste Rozière, Naman Goyal\n",
      "Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin\n",
      "Edouard Grave∗, Guillaume Lample∗\n",
      "Meta AI\n",
      "Abstract\n",
      "We introduce LLaMA, a collection of founda-\n",
      "tion language models ranging from 7B to 65B\n",
      "parameters. We train our models on trillions\n",
      "of tokens, and show that it is possible to train\n",
      "state-of-the-art models using publicly avail-\n",
      "able datasets exclusively, without resorting\n",
      "to proprietary and inaccessible datasets. In\n",
      "particular, LLaMA-13B outperforms GPT-3\n",
      "(175B) on most benchmarks, and LLaMA-\n",
      "65B is competitive with the best models,\n",
      "Chinchilla-70B and PaLM-540B. We release\n",
      "all our models to the research community1.\n",
      "1 Introduction\n",
      "Large Languages Models (LLMs) trained on mas-\n",
      "sive corpora of texts have shown their ability to per-\n",
      "form new tasks from textual instructions or from a\n",
      "few examples (Brown et al., 2020). These few-shot\n",
      "properties ﬁrst appeared when scaling models to a\n",
      "sufﬁcient size (Kaplan et al., 2020), resulting in a\n",
      "line of work that focuses on further scaling these\n",
      "models (Chowdhery et al., 2022; Rae et al., 2021).\n",
      "These efforts are based on the assumption that\n",
      "more parameters will lead to better performance.\n",
      "However, recent work from Hoffmann et al. (2022)\n",
      "shows that, for a given compute budget, the best\n",
      "performances are not achieved by the largest mod-\n",
      "els, but by smaller models trained on more data.\n",
      "The objective of the scaling laws from Hoff-\n",
      "mann et al. (2022) is to determine how to best\n",
      "scale the dataset and model sizes for a particular\n",
      "training compute budget. However, this objective\n",
      "disregards the inference budget, which becomes\n",
      "critical when serving a language model at scale.\n",
      "In this context, given a target level of performance,\n",
      "the preferred model is not the fastest to train but the\n",
      "fastest at inference, and although it may be cheaper\n",
      "to train a large model to reach a certain level of\n",
      "∗ Equal contribution. Correspondence: {htouvron,\n",
      "thibautlav,gizacard,egrave,glample}@meta.com\n",
      "1https://github.com/facebookresearch/llama\n",
      "performance, a smaller one trained longer will\n",
      "ultimately be cheaper at inference. For instance,\n",
      "although Hoffmann et al. (2022) recommends\n",
      "training a 10B model on 200B tokens, we ﬁnd\n",
      "that the performance of a 7B model continues to\n",
      "improve even after 1T tokens.\n",
      "The focus of this work is to train a series of\n",
      "language models that achieve the best possible per-\n",
      "formance at various inference budgets, by training\n",
      "on more tokens than what is typically used. The\n",
      "resulting models, called LLaMA, ranges from 7B\n",
      "to 65B parameters with competitive performance\n",
      "compared to the best existing LLMs. For instance,\n",
      "LLaMA-13B outperforms GPT-3 on most bench-\n",
      "marks, despite being 10× smaller. We believe that\n",
      "this model will help democratize the access and\n",
      "study of LLMs, since it can be run on a single GPU.\n",
      "At the higher-end of the scale, our 65B-parameter\n",
      "model is also competitive with the best large lan-\n",
      "guage models such as Chinchilla or PaLM-540B.\n",
      "Unlike Chinchilla, PaLM, or GPT-3, we only\n",
      "use publicly available data, making our work com-\n",
      "patible with open-sourcing, while most existing\n",
      "models rely on data which is either not publicly\n",
      "available or undocumented (e.g. “Books – 2TB” or\n",
      "“Social media conversations”). There exist some\n",
      "exceptions, notably OPT (Zhang et al., 2022),\n",
      "GPT-NeoX (Black et al., 2022), BLOOM (Scao\n",
      "et al., 2022) and GLM (Zeng et al., 2022), but none\n",
      "that are competitive with PaLM-62B or Chinchilla.\n",
      "In the rest of this paper, we present an overview\n",
      "of the modiﬁcations we made to the transformer\n",
      "architecture (Vaswani et al., 2017), as well as our\n",
      "training method. We then report the performance of\n",
      "our models and compare with others LLMs on a set\n",
      "of standard benchmarks. Finally, we expose some\n",
      "of the biases and toxicity encoded in our models,\n",
      "using some of the most recent benchmarks from\n",
      "the responsible AI community.\n",
      "arXiv:2302.13971v1  [cs.CL]  27 Feb 2023\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../assets/2302.13971v1.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    \n",
    "# print(f\"{pages[0].metadata}\\n\")\n",
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436311ba",
   "metadata": {},
   "source": [
    "### Vector search over PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6500f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 2 Approach\n",
      "Our training approach is similar to the methods\n",
      "described in previous work (Brown et al., 2020;\n",
      "Chowdhery et al., 2022), and is inspired by the\n",
      "Chinchilla scaling laws (Hoffmann et al., 2022).\n",
      "We train large transformers on a large quantity of\n",
      "textual data using a standard optimizer.\n",
      "2.1 \n",
      "\n",
      "\n",
      "Page 0: LLaMA: Open and Efﬁcient Foundation Language Models\n",
      "Hugo Touvron∗, Thibaut Lavril∗, Gautier Izacard ∗, Xavier Martinet\n",
      "Marie-Anne Lachaux, Timothee Lacroix, Baptiste Rozière, Naman Goyal\n",
      "Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin\n",
      "Edouard Grave∗, Guillaume Lample∗\n",
      "Meta AI\n",
      "Abstract\n",
      "W\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embedding=OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama3.2:3b\")\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(documents=pages[0:2], embedding=embedding)\n",
    "\n",
    "search_text = \"LLaMA is a collection of foundation language models, released by Meta. Unlike GPT models, \\\n",
    "LLaMA models are open-source, i.e., model weights are released to the research community under a noncommercial \\\n",
    "license. Thus, the LLaMA family grows rapidly as these models are widely used by many research groups to develop \\\n",
    "better open-source LLMs to compete the closed-source ones or to develop task-specific LLMs for mission-critical applications.\"\n",
    "\n",
    "docs = vector_store.similarity_search(search_text, k=2)\n",
    "\n",
    "for doc in docs:\n",
    "    print(f\"Page {doc.metadata['page']}: {doc.page_content[:300]}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b2054a",
   "metadata": {},
   "source": [
    "### Layout analysis and extraction of text from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3440a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires account and UNSTRUCTURED_API_KEY  from Unstructured.io\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "loader = UnstructuredLoader(\n",
    "    file_path=file_path,\n",
    "    strategy=\"hi_res\",\n",
    "    partition_via_api=True,\n",
    "    coordinates=True,\n",
    ")\n",
    "docs = []\n",
    "for doc in loader.lazy_load():\n",
    "    docs.append(doc)\n",
    "    \n",
    "print(len(docs))\n",
    "\n",
    "first_page_docs = [doc for doc in docs if doc.metadata.get(\"page_number\") == 1]\n",
    "\n",
    "for doc in first_page_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe9718",
   "metadata": {},
   "source": [
    "### Extracting tables and other structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"../assets/layout-parser-paper.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "    \n",
    "\n",
    "def plot_pdf_with_boxes(pdf_page, segments):\n",
    "    pix = pdf_page.get_pixmap()\n",
    "    pil_image = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(pil_image)\n",
    "    categories = set()\n",
    "    category_to_color = {\n",
    "        \"Title\": \"orchid\",\n",
    "        \"Image\": \"forestgreen\",\n",
    "        \"Table\": \"tomato\",\n",
    "    }\n",
    "    for segment in segments:\n",
    "        points = segment[\"coordinates\"][\"points\"]\n",
    "        layout_width = segment[\"coordinates\"][\"layout_width\"]\n",
    "        layout_height = segment[\"coordinates\"][\"layout_height\"]\n",
    "        scaled_points = [\n",
    "            (x * pix.width / layout_width, y * pix.height / layout_height)\n",
    "            for x, y in points\n",
    "        ]\n",
    "        box_color = category_to_color.get(segment[\"category\"], \"deepskyblue\")\n",
    "        categories.add(segment[\"category\"])\n",
    "        rect = patches.Polygon(\n",
    "            scaled_points, linewidth=1, edgecolor=box_color, facecolor=\"none\"\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Make legend\n",
    "    legend_handles = [patches.Patch(color=\"deepskyblue\", label=\"Text\")]\n",
    "    for category in [\"Title\", \"Image\", \"Table\"]:\n",
    "        if category in categories:\n",
    "            legend_handles.append(\n",
    "                patches.Patch(color=category_to_color[category], label=category)\n",
    "            )\n",
    "    ax.axis(\"off\")\n",
    "    ax.legend(handles=legend_handles, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def render_page(doc_list: list, page_number: int, print_text=True) -> None:\n",
    "    pdf_page = fitz.open(file_path).load_page(page_number - 1)\n",
    "    page_docs = [\n",
    "        doc for doc in doc_list if doc.metadata.get(\"page_number\") == page_number\n",
    "    ]\n",
    "    segments = [doc.metadata for doc in page_docs]\n",
    "    plot_pdf_with_boxes(pdf_page, segments)\n",
    "    if print_text:\n",
    "        for doc in page_docs:\n",
    "            print(f\"{doc.page_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_page(docs, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d6a61",
   "metadata": {},
   "source": [
    "## Load webpages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a31076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
