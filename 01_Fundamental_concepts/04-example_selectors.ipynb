{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9442ff87",
   "metadata": {},
   "source": [
    "# Example Selectors\n",
    "\n",
    "Example Selectors are responsible for selecting the correct few shot examples to pass to the prompt.\n",
    "\n",
    "- use example selectors\n",
    "- select examples by length\n",
    "- select examples by semantic similarity\n",
    "- select examples by semantic ngram overlap\n",
    "- select examples by maximal marginal relevance\n",
    "- select examples from LangSmith few-shot datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e93734",
   "metadata": {},
   "source": [
    "## Selectors by length similarity \n",
    "\n",
    "If you have a large number of examples, you may need to select which ones to include in the prompt. The Example Selector is the class responsible for doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f31f064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors.base import BaseExampleSelector\n",
    "\n",
    "class CustomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        # This assumes knowledge that part of the input will be a 'text' key\n",
    "        new_word = input_variables[\"input\"]\n",
    "        new_word_length = len(new_word)\n",
    "\n",
    "        # Initialize variables to store the best match and its length difference\n",
    "        best_match = None\n",
    "        smallest_diff = float(\"inf\")\n",
    "\n",
    "        # Iterate through each example\n",
    "        for example in self.examples:\n",
    "            # Calculate the length difference with the first word of the example\n",
    "            current_diff = abs(len(example[\"input\"]) - new_word_length)\n",
    "\n",
    "            # Update the best match if the current one is closer in length\n",
    "            if current_diff < smallest_diff:\n",
    "                smallest_diff = current_diff\n",
    "                best_match = example\n",
    "\n",
    "        return [best_match]\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"hi\", \"output\": \"ciao\"},\n",
    "    {\"input\": \"bye\", \"output\": \"arrivederci\"},\n",
    "    {\"input\": \"soccer\", \"output\": \"calcio\"},\n",
    "]\n",
    "\n",
    "example_selector = CustomExampleSelector(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89dc0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'soccer', 'output': 'calcio'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"hello\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca83a2",
   "metadata": {},
   "source": [
    "## Selectors by semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464b6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c44ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    examples,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"llama3.2:3b\"),\n",
    "    # The VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    Chroma,\n",
    "    # The number of examples to produce.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c5e49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: worried\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Input is a feeling, so should select the happy/sad example\n",
    "print(similar_prompt.format(adjective=\"worried\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b1540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: large\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Input is a measurement, so should select the tall/short example\n",
    "print(similar_prompt.format(adjective=\"large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfa3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
